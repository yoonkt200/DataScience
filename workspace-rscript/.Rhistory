train = A1[1:(n1*0.7),]
test = A1[-(1:(n1*0.7)),]
n1
ind3 = sample(2, n1, replace = T, prob = c(0.7, 0.3))
sample(2,10)
sample(2,10,replace = F)
ind3 = sample(2, 10, replace = T, prob = c(0.7, 0.3))
ind3 = sample(2, n1, replace = T, prob = c(0.7, 0.3))
ind3
ind3 = sample(3, n1, replace = T, prob = c(0.7, 0.3))
table(ind3)
train2 = iris[ind3 == 1]
train2 = iris[ind3 == 1,]
test2 = iris[ind3 == 2,]
install.packages('sampling')
library(sampling)
x = strata(c("Species"),
size = c(3, 3, 3),
method = "srswor",
data = iris)
x
x = strata(c("Species"),
size = c(3, 3, 1),
method = "srswor", # srswor : replace F // srswr : replace T
data = iris)
x
x = strata(c("Species", "Petal.Length"),
size = c(3, 3, 1),
method = "srswor", # srswor : replace F // srswr : replace T
data = iris)
x = strata(c("Species"),
size = c(3, 3, 1),
method = "srswor", # srswor : replace F // srswr : replace T
data = iris)
x
getdata(iris,x)
rep(c(3,7), c(3,2))
rep(c(3,7), c(3,2))
rep(c(3,7), each=3)
rep(1:15, length.out=15)
rep(1:10, length.out=15)
strata(c("Species", "Species2"), size=c(1,1,1,1,1,1), method="srswr", data=iris)
iris$Species2 = rep(1:2, 75)
strata(c("Species", "Species2"), size=c(1,1,1,1,1,1), method="srswr", data=iris)
rep(1:2, 75)
rep(1:2, 75)
rep(1:2, 75)
strata(c("Species", "Species2"), size=c(1,1,1,1,1,1), method="srswr", data=iris)
strata(c("Species", "Species2"), size=c(2,1,1,1,1,1), method="srswr", data=iris)
strata(c("Species", "Species2"), size=c(5,1,1,1,1,1), method="srswr", data=iris)
library(doBy)
sampleBy(~Species+Species2, frac = 0.3, data = A1)
View(A1)
for (i in seq(sample(1:10, 1)))
seq(sample(1:10, 1))
seq(sample(1:10, 1))
seq(sample(1:10, 1))
seq(sample(1:10, 1))
seq(sample(1:10, 1))
d1 = data.frame()
for (i in seq(sample(1:10, 1))){
print(i)
#d2 = iris[i, ]
}
for (i in seq(sample(1:10, 1))){
print(i)
#d2 = iris[i, ]
}
for (i in seq(sample(1:10, 1))){
d2 = iris[i, ]
d1 = rbind(d1, d2)
}
d1 = data.frame()
for (i in seq(sample(1:10, 1))){
d2 = iris[i, ]
d1 = rbind(d1, d2)
}
d1
d <- data.frame(x=c("1","2","2","1"), y=c("A","B","A","B"), num=c(3,5,8,7))
d
table(d$x, d$y)
d$x
d$y
table(d$x, d$y)
d_bind = rbind(d,d)
table(d_bind$x, d_bind$y)
View(d_bind)
xtabs(num ~ x+y, data=d_bind)
View(d_bind)
table(d_bind$x)
table(d_bind$x, d_bind$y)
xtabs(num ~ x+y, data=d)
View(d)
xt = xtabs(num ~ x+y, data=d)
margin.table(xt)
xt = xtabs(num ~ x+y, data=d_bind)
margin.table(xt)
sum(xt)
margin.table(xt)
margin.table(xt, 1)
margin.table(xt, 2)
xt
d1
prop.table(xt, 1)
tot = sum(xt)
p_xt = prop.table(xt)
str(p_xt)
p_xt
m_xt = as.matrix(p_xt)
str(m_xt)
m_xt
m_xt = as.matrix(p_xt)
str(m_xt)
tot*p_xt[[1]][1]
p_xt[[1]][1]
str(p_xt)
p_xt
data("survey")
data(survey)
library(MASS)
data('survey')
View(survey)
xt = xtabs(~Sex+Enter, data = survey)
xt = xtabs(~Sex+Exer, data = survey)
xt
View(survey)
chi1 = chisq.test(xt)
chi1
str(chi1)
chi1$statistic
str(chi1)
fisher.test(xt)
chi1 = chisq.test(xt) # ???
chi1
fisher.test(xt)
fisher.test(xtabs(~W.Hnd+Clap, data = survey))
A1
View(A1)
iris$Species2 = rep(1:2, 75)
strata(c("Species", "Species2"), size=c(5,1,1,1,1,1), method="srswr", data=iris)
sampleBy(~Species+Species2, # ???
frac = 0.3,
data = A1)
sampleBy(~Species+Species2, # ???
frac = 0.3,
data = iris)
table(iris)
table(iris$Species)
table(iris$Species+Species2)
iris$Species2 = rep(1:2, 75)
table(iris$Species+Species2)
table(iris$Species)
table(iris$Species2)
table(iris$Species)
sampleBy(~Species+Species2, # ???
frac = 0.3,
data = iris)
sampleBy(~Species+Species2+Sepal.Length, # ???
frac = 0.3,
data = iris)
sampleBy(~Species+Species2, # ???
frac = 0.3,
data = iris)
te = sampleBy(~Species+Species2, # Spcecies 1, 2 를 묶은것을 하나의 그룹으로 보는 것.
frac = 0.3,
data = iris)
table(te)
str(te)
te = sampleBy(~Species+Species2, # Spcecies 1, 2 를 묶은것을 하나의 그룹으로 보는 것.
frac = 0.3,
data = iris)
te
d1 = data.frame()
for (i in seq(sample(1:10, 1))){
d2 = iris[i, ]
d1 = rbind(d1, d2)
}
d1
xt = xtabs(~Sex+Exer, data = survey)
View(survey)
View(xt)
xt
chi1 = chisq.test(xt) # ???
chi1
str(chi1)
chi1$statistic
chi1
str(chi1)
var.test(x=data1, y=data2)
data1 = rnorm(100, mean=180, sd=10)
t.test(x=data1, mu=180)
t.test(x=data1, mu=200)
data2 = rnorm(100, mean=160, sd=5)
var.test(x=data1, y=data2)
t.test(x=data1, y=data2, var.equal = F)
chi1
str(chi1)
chi1$statistic
fisher.test(xtabs(~W.Hnd+Clap, data = survey)) # ???
vif(model2) # 10이 넘는 값 두개가 있으므로 다중 공선성 문제 존재.
model3 = lm(Sepal.Length ~ Sepal.Width, train)
model1 = lm(dist ~ speed, cars)
library(car)
durbinWatsonTest(model1$residuals)
predict(model1, newdata = data.frame(speed=c(3,7)))
n = nrow(iris)
set.seed(200)
ind = sample(1:n, n*0.7, replace = F)
train = iris[ind,]
test = iris[-ind,]
model2 = lm(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, train)
summary(model2)
durbinWatsonTest(model2$residuals)
vif(model2) # 10이 넘는 값 두개가 있으므로 다중 공선성 문제 존재.
svm1 = svm(y1~x2, data)
library(e1071)
svm1 = svm(y1~x2, data)
library(car)
n = nrow(iris)
set.seed(200)
ind = sample(1:n, n*0.7, replace = F)
train = iris[ind,]
test = iris[-ind,]
model2 = lm(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, train)
model3 = lm(Sepal.Length ~ Sepal.Width, train)
model4 = lm(Sepal.Length ~ Sepal.Width + Petal.Length, train)
library(mlbench)
x = sample(0:2*pi, 1000, replace=T)
y = sin(x)
e = rnorm(1000, 0, 1)
y_e = y+e
y_e = y+e
x1 = seq(0, 2*pi, 0.01)
data = data.frame()
for(i in x1){
e1 = rnorm(10, 0, sample(1:3, 1, replace = T))
y1 = sin(i) + e1
x2 = rep(i, 10) # rep -> repeat의 약자
data1 = cbind(x2, y1)
data = rbind(data, data1)
}
library(e1071)
svm1 = svm(y1~x2, data)
pred1 = predict(svm1, newdata = data)
points(data$x2, pred1, col = 'red', pch = "*", cex = 0.3)
points(data$x2, sin(data$x2), col='blue', pch="#", cex=0.4)
plot(data, cex=0.1)
points(data$x2, pred1, col = 'red', pch = "*", cex = 0.3)
pred1 = predict(svm1, newdata = test)
txt = readLines('big.txt', encoding = "UTF-8")
length(txt) # vector data count
nrow(iris) # data frame count
length(iris) # data frame column count
buildDictionary(user_dic = data.frame(c("빅데이터", "ncn")), replace_usr_dic = F)
txt0 = str_to_lower(txt)
txt1 = gsub("빅데이타", "빅데이터", txt0)
txt1 = gsub("bigdata", "빅데이터", txt1)
txt1 = gsub("big data", "빅데이터", txt1)
txt1 = gsub("[[:digit:]]", "", txt1)
txt1 = gsub("[[A-z]]", "", txt1)
txt1 = gsub("[[:punct:]]", "", txt1)
txt1 = gsub("  ", " ", txt1)
txt2 = txt1[str_length(txt1)>1] # remove empty line
txt_e = extractNoun(txt2)
txt_t = table(unlist(txt_e))
txt_s = sort(txt_t, decreasing = T)
txt_s1 = txt_s[str_length(names(txt_s)) > 1] # remove one character words
txt_h = head(txt_s1, 5)
barplot(txt_h)
pal1 = brewer.pal(7, "Set1")
wordcloud(names(txt_s1),
txt_s1, # data : must be table class
scale=c(5, 0.5), # string size max, min
min.freq = 2, # word freq min
random.order = F, # location random
rot.per = 0.2, # rotation percent
family="AppleGothic")
library(KoNLP)
setwd("/Users/yoon/Documents/DataScience/R_work")
streetlamp <- read.csv('streetlamp.csv',header= T)
streetlamp
View(streetlamp)
streetlamp <- read.csv('streetlamp.csv',header= T, fileEncoding = "UTF-8")
streetlamp <- read.csv('streetlamp.csv',header= T, fileEncoding = "UTF-8")
streetlamp <- read.csv('streetlamp.csv',header= T, fileEncoding = "eru-ko")
streetlamp <- read.csv('streetlamp.csv',header= T, fileEncoding = "eru-ko")
streetlamp <- read.csv('streetlamp.csv',header= T, fileEncoding = "euc-kr")
setwd("/Users/yoon/Documents/DataScience/R_work")
streetlamp <- read.csv('streetlamp.csv',header= T, fileEncoding = "euc-kr")
dyn.load("/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre/lib/server/libjvm.dylib")
library(rJava)
Sys.setlocale("LC_ALL", "ko_KR.UTF-8")
streetlamp <- read.csv('streetlamp.csv',header= T, fileEncoding = "euc-kr")
streetlamp
tidy_streetlamp <- melt(streetlamp, value.name = "count")
library(reshape2)
library(dplyr)
tidy_streetlamp <- melt(streetlamp, value.name = "count")
head(tidy_streetlamp)
dcast_streetlamp <- dcast(tidy_streetlamp, X ~ variable, value.var = "count" )
head(dcast_streetlamp)
dcast_streetlamp <- dcast(tidy_streetlamp, variable ~ ㅌ, value.var = "count" )
dcast_streetlamp <- dcast(tidy_streetlamp, variable ~ X, value.var = "count" )
head(dcast_streetlamp)
dcast_streetlamp <- dcast(tidy_streetlamp, X ~ variable, value.var = "count" )
head(dcast_streetlamp)
tidy_streetlamp$year = gsub("X|년","", tidy_streetlamp$year)
head(tidy_streetlamp)
dplyr_streetlamp <- melt(streetlamp, value.name = "count")
head(dplyr_streetlamp)
dplyr_streetlamp <- mutate(dplyr_streetlamp, year = gsub("X|년", "",variable))
head(dplyr_streetlamp)
year_streetlamp <- group_by(dplyr_streetlamp, year)
head(year_streetlamp)
View(year_streetlamp)
View(dplyr_streetlamp)
library(networkD3)
library(dplyr)
library(yaml)
install.packages("networkD3")
library(networkD3)
data(MisLinks,MisNodes)
MisLinks
MisNodes
force_network = forceNetwork(Links = MisLinks, Nodes = MisNodes,
width = 500,
Source = 'source', Target = 'target',
Value = 'value',
NodeID = 'name', Group = 'group',
opacity = 0.9)
force_network
geocode('Seoul',output = 'latlona') # 위도,경도 반환 source : google
library(ggmap)
library(ggplot2)
library(leaflet)
install.packages("ggmap")
install.packages("leaflet")
library(ggmap)
library(ggplot2)
library(leaflet)
geocode('Seoul',output = 'latlona') # 위도,경도 반환 source : google
station_list = c('시청역','을지로입구역','을지로3가역','을지로4가역',
'동대문역사문화공원','신당역','상왕십리역','왕십리역',
'한양대역','뚝섬역','성수역','건대입구역','구의역',
'강변역','잠실나루역','잠실역','신천역','종합운동장역',
'삼성역','선릉역','역삼역','강남역','2호선 교대역',
'서초역','방배역','사당역','낙성대역','서울대입구역',
'봉천역','신림역','신대방역','구로디지털단지역','대림역',
'신도림역','문래역','영등포구청역','당산역','합정역',
'홍대입구역','신촌역','이대역','아현역','충정로역')
station_df = data.frame(station_list, stringsAsFactors=FALSE)
station_df
station_df$station_list = enc2utf8(station_df$station_list)
station_df
rm(mutate_geocode)
station_lonlat = mutate_geocode(station_df, station_list, source = 'google')
station_lonlat
qmap('seoul',zoom = 11, maptype = 'roadmap') # 지도, seoul 은 서울을 가운데로 놓고 보겠다.
qmap('seoul',zoom = 11, maptype = 'toner') # 지도를 흑백으로
qmap('seoul',zoom = 11, maptype = 'watercolor')
seoul_map <- qmap('seoul', zoom = 11, maptype = 'roadmap')
seoul_map
seoul_map + geom_point(data = station_lonlat,
aes(x = lon, y = lat),
colour = 'red',
size = 2.5)
setwd("/Users/yoon/Documents/DataScience/week4_Visualization")
setwd("/Users/yoon/Documents/DataScience/R_work")
setwd("C:/Users/ajou/Desktop/DataScience/R_work")
setwd("C:/Users/ajou/Desktop/DataScience/R_work")
setwd("/Users/yoon/Documents/DataScience/R_work")
teens = read.csv("snsdata.csv", header = T, stringsAsFactors = F, sep = ",")
table(teens$gender, useNA = "ifany")
summary(teens$age)
teens$age <- ifelse(teens$age >= 13 & teens$age < 20, teens$age, NA)
teens$female <- ifelse(teens$gender == 'F', 1, 0)
teens$no_gender <- ifelse(is.na(teens$gender), 1, 0)
ave_age <- ave(teens$age, teens$gradyear, FUN = function(x) mean(x, na.rm = T))
teens$age <- ifelse(is.na(teens$age), ave_age, teens$age)
table(teens$age, useNA = "ifany")
length(which(teens$age == NA))
interests <- teens[, 5:40]
interests_z <- scale(interests)
teens_cluster <- kmeans(interests_z, 5)
table(teens_cluster$cluster)
teens_cluster$centers
teens$cluster <- teens_cluster$cluster
aggregate(data=teens, age ~ cluster, mean)
teens$cluster
teens[1:5, c("cluster", "gender", "age", "friends")]
aggregate(data = teens, age ~ cluster, mean)
aggregate(data = teens, female ~ cluster, mean)
View(teens)
aggregate(data = teens, friends ~ cluster, mean)
setwd("/Users/yoon/Documents/DataScience/R_work")
setwd("/Users/yoon/Documents/DataScience/R_work")
setwd("/Users/yoon/Documents/DataScience/R_work")
setwd("/Users/yoon/Documents/DataScience/R_work")
mobile <- read.csv('mobile2014.csv', stringsAsFactors = F)
dim(mobile)
names(mobile)
mobile[2,]
mobile[1035,]
table(mobile$Sentiment)
library(tm)
corpus <- Corpus(VectorSource(mobile$Texts))
corpus <- Corpus(VectorSource(mobile$Texts)) # 문서 만들기
stopwords() # 시스템 디폴트
stopwords("SMART") # 제거할 목록 명단
stopwords("SMART") # 제거할 목록 명단
stwds = stopwords("SMART") # 제거할 목록 명단 = 불용어 사전(너무 자주쓰여서 의미가 없는 단어들)
dtm <- DocumentTermMatrix(corpus,
control = list(tolower = T,
removePunctuation = T,
removeNumbers = T,
stopwords = stwds,
weighting = weightTfIdf))
dtm
install.packages("tm.plugin.sentiment", repos = "http://R-Forge.R-project.org")
install.packages("glmnet")
library(tm.plugin.sentiment)
install.packages("tm.plugin.sentiment", repos = "http://R-Forge.R-project.org")
library(tm.plugin.sentiment)
install.packages("tm.plugin.sentiment")
X <- as.matrix(dtm)
Y <- mobile$Sentiment
res.lm <- glmnet(X, Y, family = "binomial", lambda = 0)
library(devtools) # try install.packages('devtools') if you don't have it installed
install_github("mannau/tm.plugin.sentiment")
library(tm.plugin.sentiment) # should work
library(tm.plugin.sentiment)
res.lm <- glmnet(X, Y, family = "binomial", lambda = 0)
library(glmnet)
X <- as.matrix(dtm)
Y <- mobile$Sentiment
res.lm <- glmnet(X, Y, family = "binomial", lambda = 0)
inspect(dtm[1:20])
inspect(dtm[1:20,])
str(dtm)
dtm
colnames(dtm)
X <- as.matrix(dtm)
View(X)
Y <- mobile$Sentiment
View(X)
View(mobile)
X <- as.data.frame(dtm)
str(X)
length(pos.lm)
coef(res.lm)
coef.lm <- coef(res.lm)[ ,1] # 회귀계수만 저장
pos.lm <- coef.lm[coef.lm > 0] # 0보다 큰 계수만 저장
neg.lm <- coef.lm[coef.lm < 0] # 0보다 작은 계수만 저장
pos.lm <- sort(pos.lm, decreasing = T) #회귀계수 크기대로 정렬 후 저장
neg.lm <- sort(neg.lm, decreasing = F) #회귀계수 크기대로 정렬 후 저장
length(pos.lm)
pos.lm
senti.lm <- polarity(dtm, names(pos.lm), names(neg.lm))
senti.lm.b <- ifelse(senti.lm > 0, 1, 0)
confusionMatrix(senti.lm.b, mobile$Sentiment)
library(caret)
install.packages("caret")
library(caret)
confusionMatrix(senti.lm.b, mobile$Sentiment)
set.seed(12345)
res.lasso <- cv.glmnet(X, Y, family = "binomial", alpha = 1,
nfolds = 4, type.measure = "class")
plot(res.lasso)
plot(res.lasso$glmnet.fit, xvar = "lambda")
setwd("/Users/yoon/Documents/DataScience/R_work")
install.packages("arules")
library(arules)
setwd("/Users/yoon/Documents/DataScience/R_work")
groceries <- read.transactions("groceries.csv",sep=",")
groceries <- read.transactions("groceries.csv",sep=",")
inspect(groceries[1:5])
itemFrequency(groceries[,1:3])
itemFrequency(groceries[,1:10])
groceries[,1:10]
inspect(groceries[1:10])
itemFrequency(groceries[,1:10])
itemFrequency(groceries[,1:1])
itemFrequency(groceries[,1:10])
itemFrequency(groceries[1:10,1:10])
inspect(groceries[1:10,])
inspect(groceries[,1:10])
inspect(groceries[1:10])
groceries[1]
itemFrequency(groceries[,1:3])
groceries[,1]
a=groceries[,1]
a
groceries
itemFrequency(groceries[,1:3])
itemFrequencyPlot(groceries, support=0.1)
itemFrequencyPlot(groceries, topN=20)
itemFrequencyPlot(groceries, support=0.1)
inspect(groceries[1:10])
itemFrequencyPlot(groceries, topN=20)
image(groceries[1:5])
image(sample(groceries, 100))
setwd("/Users/yoon/Documents/DataScience/R_work")
dyn.load("/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre/lib/server/libjvm.dylib")
library(rJava)
Sys.setlocale("LC_ALL", "ko_KR.UTF-8") # 한글 인코딩 가능하게 해줌
library(MASS)
data("survey")
View(survey)
model1 = aov(Pulse ~ Exer, data=survey)
summary(model1)
model2 = aov(Sepal.Length ~ Species, data=iris)
summary(model2)
