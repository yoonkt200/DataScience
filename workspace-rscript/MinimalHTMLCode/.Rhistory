pal01 <- brewer.pal(9, "Set1")
wordcloud(names(txt_count), freq=txt_count, scale=c(5,1), rot.per = 0.25, min.freq=1, random.order=F, random.color=T, colors=pal01)
install.packages("shiny")
library(shiny)
runExample("01_hello")
runExample("08_html")
runExample()
runGist(6571951)
View(news())
setwd("C:/r_test")
x = 3
y = 5
x1 <- 6
6 -> y1
iris
head(iris,10)
iris01 <- head(iris,10)
x = 3
y = 5
# 데이터
x1 <- 6
6 -> y
iris01 <- head(iris,10)
iris01 <- head(iris,10) # iris 추출
x2 <- 1:10
x3 <- c(3,5,7,10)
x4 <- data.frame(1,3,5,7)
x5 <- data.frame(a=c(1,3,5,7), b=c(4,7,9,10))
x5
x5[a]
x5["a"]
x5[,2]
x4[2]
View(x4)
View(x5)
str(iris)
View(iris)
x3[x3>6]
iris[,iris[3]>1.4]
iris[iris[3]>1.4]
x7 <- iris[,3]
x7[x7>1.4]
View(x4)
View(iris01)
names(iris)
iris02 <- iris
names(iris02) <- c("SL", "SW","PL","PW","S")
iris02
iris02$SL
x8 <- data.frame()
View(x8)
edit(x8)
f <- file("big.txt",encoding = "UTF-8")
fl <- readLines(f)
close(f)
fl
library(KoNLP)
library(RColorBrewer)
library(wordcloud)
ext_txt01 <- sapply(fl, extractNoun, USE.NAMES = F)
ext_txt01
str(ext_txt01)
ext_txt02 <- table(unlist(ext_txt01))
ext_txt02
? wordcloud
?brewer.pal
pal <- brewer.pal(7, "Set1")
wordcloud(names(ext_txt02), freq=ext_txt02, scale=c(5,1),min.freq = 1, rot.per = 0.1, random.order = F, col=pal)
fl2 <- gsub("7.", "", fl)
fl2 <- gsub("to", "", fl2)
ext_txt01 <- sapply(fl2, extractNoun, USE.NAMES = F)
ext_txt02 <- table(unlist(ext_txt01))
pal <- brewer.pal(7, "Set1")
wordcloud(names(ext_txt02), freq=ext_txt02, scale=c(5,1),min.freq = 1, rot.per = 0.1, random.order = F, col=pal)
fl2 <- gsub("7.", "", fl)
fl2 <- gsub("to", "", fl2)
fl2 <- gsub("\\d", "", fl2)
ext_txt01 <- sapply(fl2, extractNoun, USE.NAMES = F)
ext_txt02 <- table(unlist(ext_txt01))
pal <- brewer.pal(7, "Set1")
wordcloud(names(ext_txt02), freq=ext_txt02, scale=c(5,1),min.freq = 1, rot.per = 0.1, random.order = F, col=pal)
fl2 <- gsub("\\E", "", fl2)
ext_txt01 <- sapply(fl2, extractNoun, USE.NAMES = F)
ext_txt02 <- table(unlist(ext_txt01))
pal <- brewer.pal(7, "Set1")
wordcloud(names(ext_txt02), freq=ext_txt02, scale=c(5,1),min.freq = 1, rot.per = 0.1, random.order = F, col=pal)
fl2 <- gsub("[:alpha:]", "", fl2)
ext_txt01 <- sapply(fl2, extractNoun, USE.NAMES = F)
ext_txt02 <- table(unlist(ext_txt01))
pal <- brewer.pal(7, "Set1")
wordcloud(names(ext_txt02), freq=ext_txt02, scale=c(5,1),min.freq = 1, rot.per = 0.1, random.order = F, col=pal)
fl2 <- gsub("[a-z]", "", fl2)
ext_txt01 <- sapply(fl2, extractNoun, USE.NAMES = F)
ext_txt02 <- table(unlist(ext_txt01))
pal <- brewer.pal(7, "Set1")
wordcloud(names(ext_txt02), freq=ext_txt02, scale=c(5,1),min.freq = 1, rot.per = 0.1, random.order = F, col=pal)
fl2 <- gsub("[A-Z]", "", fl2)
ext_txt01 <- sapply(fl2, extractNoun, USE.NAMES = F)
ext_txt02 <- table(unlist(ext_txt01))
pal <- brewer.pal(7, "Set1")
wordcloud(names(ext_txt02), freq=ext_txt02, scale=c(5,1),min.freq = 1, rot.per = 0.1, random.order = F, col=pal)
nchar(fl)
fl01<- fl[nchar(fl)>2]
nchar(fl01)
names(ext_txt02)
str_length(names(ext_txt02))
str_length("대한민국")
ext_txt03 <- ext_txt02[str_length(names(ext_txt02))> 1]
wordcloud(names(ext_txt03), freq=ext_txt03, scale=c(5,1),min.freq = 1, rot.per = 0.1, random.order = F, col=pal)
library(KoNLP)
nchar("대한민국", type="width")
nchar("대한민국", type="chars")
f <- file("txt",encoding = "UTF-8")
fl <- readLines(f)
close(f)
str_length(fl)
nchar("대한민국")
nchar(fl, type="bytes")
nchar(fl, type="chars")
nchar(fl, type="width")
install.
install.packages("Rcmdr",dependencies=T)
library(Rcmdr)
sex <- factor("m", c("m", "f"));sex
ordered(c("b", "c", "a"))
sex <- factor("m", c("f", "m"));sex
sex <- factor("2", c("2", "3","1"));sex
seq_along(c("a", "b","c"))
seq_along(c("ab", "bc","c", "d"))
z <- scan()
z
mode(NA)
x <- seq(0,1,0.05)
x1 <- data.frame(seq(0,1,0.05), seq(0,1,0.05))
plot(x1)
x1 <- data.frame(x=seq(0,1,0.05), y=seq(0,1,0.05))
plot(x1)
plot(x)
plot(x,x)
x <- seq(0, 1, 0.05)
plot(x, x, ylab="y", type="l")
for (j in 2:18) lines(x, x^j)
example(svm)
rm(sex)
ls()
read.csv("a1.csv", header=T)
a1 <- read.csv("a1.csv", header=T)
View(a1)
write.csv(a1, “data1.csv ", row.names=F)
a1 <- read.csv("a1.csv", header=T)
write.csv(a1, "data1.csv", row.names=F)
str(a1)
a1
save(x,x2,file="exam1.RData")
save(list=ls(),file="exam2.RData")
rm(list=ls())
load("exam2.RData")
a2 <- read.table("clipboard", header=T)
a2
?? read.xls
install.packages("forean")
?? forean
library("readxl", lib.loc="~/R/win-library/3.2")
a3 <- read.table(file.choose(), header=T)
a3 <- read.table(file.choose(), header=T)
View(a3)
a3 <- read.table(file.choose(), header=T, sep=",")
View(a3)
View(a3)
aggregate(Sepal.Length~Species , iris , mean)
aggregate(iris, Species, mean)
aggregate(iris, iris$Species, mean)
iris
aggregate((Sepal.Width, Sepal.Length)~Species, iris , mean)
aggregate(cbind(Sepal.Width, Sepal.Length)~Species, iris , mean)
apply(iris,1, mean)
apply(iris[,1:4],1, mean)
head(iris,10)
apply(iris[,1:4],2, mean)
apply(iris,2, mean)
apply(iris[,1:4],2, mean)
str(iris)
tapply(iris, iris[,5], mean)
tapply(iris[,1:4], iris[,5], mean)
?tapply
str(iris)
tapply(iris, iris$Species, mean)
tapply(iris, Species, mean)
tapply(iris$Sepal.Length, iris$Species, mean)
library(doBy)
split (iris , iris $ Species )
z3 <- split (iris , iris $ Species )
str(z3)
z4 <- subset (iris , Species == " setosa ")
str(z4)
library(arules)
a_list = list(
c("a","b","c"),
c("a","b"),
c("a","b","d"),
c("c","e"),
c("a","b","d","e")
)
names(a_list) = paste("Tr",c(1:5), sep = "")
a_list
trans = as(a_list, "transactions")
summary(trans)
image(trans)
?image
a_matrix = matrix(
c(1,1,1,0,0,
1,1,0,0,0,
1,1,0,1,0,
0,0,1,0,1,
1,1,0,1,1), ncol = 5)
dimnames(a_matrix) =  list(
c("a","b","c","d","e"),
paste("Tr",c(1:5), sep = ""))
a_matrix
trans2 =  as(a_matrix, "transactions")
trans2
image(trans2)
a_data.frame = data.frame(
age = as.factor(c(6,8,7,6,9,5)),
grade = as.factor(c(1,3,1,1,4,1)))
a_data.frame
trans3 = as(a_data.frame, "transactions")
image(trans3)
a_df = sample(c(LETTERS[1:5], NA),10,TRUE)
a_df = data.frame(X = a_df, Y = sample(a_df))
a_df
trans3 = as(a_df, "transactions")
trans3
as(trans3, "data.frame")
data(Adult)
str(Adult)
rules = apriori(Adult,
parameter = list(supp = 0.5, conf = 0.9, target = "rules"))
summary(rules)
rules = apriori(Adult, parameter = list(support = 0.4))
rules.sub = subset(rules, subset = rhs %pin% "sex" & lift > 1.3)
rules.sub
pin
inspect(SORT(rules.sub)[1:3])
rules.sub = subset(rules, subset = rhs %pin% "sex" & lift > 1.3)
inspect(SORT(rules.sub)[1:3])
?`SORT,associations-method`
inspect(sort(rules.sub)[1:3])
str(Income)
data("Income")
str(Income)
View(Income)
View(Income)
In <- as(Income, "data.frame")
In2 <- as(Income, "data.frame")
View(In2)
??unique
library('devtools')
devtools::install_github('christophergandrud/d3Network')
library('RCurl')
library('d3Network')
ericOpenHtml <- function(filename) {
if (Sys.info()["sysname"]=="windows"){
shell.exec(filename)
}else {
system(paste("open",filename)) # Mac case
}
}
Source <- c("A","A","A","A","B","B","B","C","C","D","D")
Target <- c("B","C","D","G","E","F","M","J","H","I","K")
NetworkData <- data.frame(Source, Target)
d3SimpleNetwork(NetworkData, width=400, height=250, file="3d_test.html")
ericOpenHtml("3d_test.html")
library(cluster)
votes.repub[1:10, 1:3]
data(votes.repub)
agn1 <- agnes(votes.repub, metric = 'manhattan', stand=TRUE)
agn1
plot(agn1)
agn2 <- agnes(daisy(votes.repub), diss=TRUE, method = 'complete')
plot(agn2)
plot(agnS)
a <- c(1,6)
b <- c(2,4)
c <- c(5,7)
d <- c(3,5)
e <- c(5,2)
f <- c(5,1)
c_data <- data.frame(a,b,c,d,e,f)
c_data <- t(c_data)
c_data
# 거리측정
eu_dist <- round(dist(c_data, method='euclidean'), digits=2)
eu_dist
man_dist <- round(dist(c_data, method='manhattan'), digits=2)
man_dist
can_dist <- round(dist(c_data, method='canberra'), digits=2)
can_dist
min_dist <- round(dist(c_data, method='minkowski'), digits=2)
min_dist
c_labels = row.names(c_data)
plot(c_data, xlim=c(0,6), ylim=c(0,7))
text(c_data, labels=c_labels, pos=4)
dist(c_data)
{dist(c_data)}^2
# 최단연결법
(c1 <- hclust(dist(c_data)^2, method='single'))
plot(c1)
# 최장연결법
(c2 <- hclust(dist(c_data)^2, method='complete'))
plot(c2)
# 와드연결법
(c3 <- hclust(dist(c_data)^2, method='ward.D2'))
plot(c3)
# 평균연결법
(c4 <- hclust(dist(c_data)^2, method='average'))
plot(c4)
#K-means
rm(list=ls(all=TRUE))
c_iris <- iris
head(c_iris)
c_iris$Species <- NULL
head(c_iris)
(c_km <- kmeans(c_iris,3))
table(iris$Species, c_km$cluster)
plot(c_iris[c('Sepal.Length','Sepal.Width')], main='K-means', col=c_km$cluster)
plot(c_iris[c('Sepal.Length','Sepal.Width')], main='true', col=c(1,2,3)[unclass(iris$Species)])
(c_km2 <- kmeans(c_iris,4))
table(iris$Species, c_km2$cluster)
plot(c_iris[c('Sepal.Length','Sepal.Width')], main='K-means', col=c_km2$cluster)
??packageName
packageName()
View(packageName)
View(str)
library('devtools')
devtools::install_github('christophergandrud/d3Network')
library('RCurl')
library('d3Network')
ericOpenHtml <- function(filename) {
if (Sys.info()["sysname"]=="windows"){
shell.exec(filename)
}else {
system(paste("open",filename)) # Mac case
}
}
Source <- c("A","A","A","A","B","B","B","C","C","D","D")
Target <- c("B","C","D","G","E","F","M","J","H","I","K")
NetworkData <- data.frame(Source, Target)
d3SimpleNetwork(NetworkData, width=400, height=250, file="3d_test.html")
ericOpenHtml("3d_test.html")
library(KoNLP)
library(arules)
library(igraph)
library(combinat)
library(assertthat)
library(DBI)
# library(dbConnect)
rule <- file('2015park.txt', encoding = "UTF-8")
rules <- readLines(rule)
close(rule)
head(rules, 10)
tran <- Map(extractNoun, rules)
tran <- unique(tran)
tran <- sapply(tran, unique)
tran <- sapply(tran, function(x) {Filter(function(y){nchar(y)<=4 && nchar(y) > 1 && is.hangul(y)}, x)})
tran <- Filter(function(x){length(x) >= 2}, tran)
tran
names(tran) <- paste("Tr",1:length(tran), seq="")
names(tran)
wordtran <- as(tran, "transactions")
wordtran
wordtab <- crossTable(wordtran)
wordtab
## apriori 연관분석
ares <- apriori(wordtran, parameter=list(supp=0.1, conf=0.2))
## 연관분석 결과 확인
inspect(ares)
rules <- labels(ares, ruleSep=" ")
rules <- sapply(rules, strsplit, " ", USE.NAMES = F)
rulemat <- do.call("rbind", rules)
## 시각화
ruleg <- graph.edgelist(rulemat[-c(1:6),],directed = T)
plot.igraph(ruleg,
vertex.label=V(ruleg)$name,
vertex.label.cex=1,
vertex.size=30,
layout=layout.fruchterman.reingold.grid)
rulemat
ruleg
NetworkData <- rulemat[-c(1:6),]
str(NetworkData)
NetworkData <- as(NetworkData, "data.frame")
as.data.frame(NetworkData)
str(NetworkData)
NetworkData <- as.data.frame(NetworkData)
str(NetworkData)
d3SimpleNetwork(NetworkData, width=400, height=250, file="3d_test.html")
ericOpenHtml("3d_test.html")
result <- read.transactions('mybasket.csv', format='basket', sep=',')
result
summary(result)
image(result)
z1 <- as(result, "data.frame")
rules <- apriori(result, parameter=list(supp=0.1, conf=0.1))
inspect(rules)
install.packages('arulesViz')
library(arulesViz)
plot(rules)
plot(rules, method='grouped')
plot(rules, method = 'graph', control = list(type='items'))
plot(rules[-c(1:7)], method = 'graph', interactive=TRUE, control = list(type='items', cex=5, precision=30, alpha=0.2))
plot(rules[-c(1:7)], method = 'graph', interactive=TRUE, control = list(type='items', cex=5, precision=30, alpha=0.2))
rules
inspect(rules)
z1 <- as.data.frame(rules)
z1 <- as(rules, "data.frame")
z1
z1 <- rules[,1]
z1
z2 <- z1[-c(1:7), 1]
z2
rules$lhs
inspect(rules)
rule <- file('2015park.txt', encoding = "UTF-8")
rules <- readLines(rule)
close(rule)
head(rules, 10)
tran <- Map(extractNoun, rules)
tran <- unique(tran)
tran <- sapply(tran, unique)
tran <- sapply(tran, function(x) {Filter(function(y){nchar(y)<=4 && nchar(y) > 1 && is.hangul(y)}, x)})
tran <- Filter(function(x){length(x) >= 2}, tran)
tran
names(tran) <- paste("Tr",1:length(tran), seq="")
names(tran)
wordtran <- as(tran, "transactions")
wordtran
wordtab <- crossTable(wordtran)
wordtab
## apriori 연관분석
ares <- apriori(wordtran, parameter=list(supp=0.1, conf=0.2))
## 연관분석 결과 확인
inspect(ares)
rules <- labels(ares, ruleSep=" ")
(rules <- sapply(rules, strsplit, " ", USE.NAMES = F))
(rules <- labels(ares, ruleSep=" "))
?labels
str(rules)
inspect(ares)
(rules <- labels(ares, ruleSep=" "))
inspect(ares)
(rules <- labels(ares, ruleSep=" "))
(rules <- sapply(rules, strsplit, " ", USE.NAMES = F))
(rulemat <- do.call("rbind", rules))
ruleg <- graph.edgelist(rulemat[-c(1:6),],directed = T)
plot.igraph(ruleg,
vertex.label=V(ruleg)$name,
vertex.label.cex=1,
vertex.size=30,
layout=layout.fruchterman.reingold.grid)
library(Rfacebook)
library(Rook)
library(stringr)
library(wordcloud)
library(RColorBrewer)
library(KoNLP)
token <- "CAACEdEose0cBAJ9DeZBWeuxZBn0DtMxmByFNiU8QYCvif9KsfDriHwXkGBcMsazTyqa5TCBwvd4PfDYv56PDGjbZATRDuK9cVmCA6QZC29KRHwbJlnNBqvZBhgnvEPxzU7ZBQMTSBMWIfjZA00sqaZAgKK95DuznfhVRm11eKWuzcF4l0y5mCsWe2n4A1GRzOLMgiN9Rca8ULhQA8z1spRZAT"
timeline <- getPage(page="statsas", token, n=5000)
data1 <- timeline$message
str(data1)
data1
data1 <- data1[!is.na(data1)]
data1
data2 <- sapply(data1, extractNoun, USE.NAMES=F)
data2
data3 <- unlist(data2)
data3 <- Filter(function(x) {nchar(x)>=2}, data3)
data3 <- gsub("-", "", data3)
data3 <- gsub("[A-z]", "", data3)
write(unlist(data3), "facebook1.txt")
data4 <- read.table("facebook1.txt")
data4 <- read.table("facebook1.txt")
wordcount<-table(data4)
wordcount
library(RColorBrewer)
palete <- brewer.pal(9,"Set1")
wordcloud(names(wordcount), freq=wordcount,scale=c(5,0.3),
rot.per=0.25,min.freq=100,random.order=F,random.color=T,
colors=palete)
wordcloud(names(wordcount), freq=wordcount,scale=c(5,0.3),
rot.per=0.25,min.freq=5,random.order=F,random.color=T,
colors=palete)
library("ggplot2", lib.loc="~/R/win-library/3.2")
mpg
table(mpg$class)
barplot(table(mpg$class), main="Base graphics")
ggplot(data=mpg, aes(x=class))+geom_bar()+ggtitle("ggplot2")
??resize
??image
longley
plot(x=longley$Year, y=longley$GNP, type='l', xlab = "Year", main = "Base graphics")
ggplot(longley, aes(x=1947:1962, y=GNP))+geom_line()+xlab("Year")+ggtitle("ggplot2")
library(shiny)
runExample("01_hello")
runExample("08_hello")
runExample("08_html")
runExample("01_hello")
?p
runExample("01_hello")
faithful
runExample("01_hello")
setwd("C:/r_test/MinimalHTMLCode")
